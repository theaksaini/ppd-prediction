{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b2027b5e-e41c-478f-9f62-0401792651f6",
   "metadata": {},
   "source": [
    "Author: Emily Wong \\\n",
    "February 16, 2023"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec0f048c-bd13-431b-b79d-b1de4b1c8476",
   "metadata": {},
   "source": [
    "# Resources"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4abf5e9c-bc94-410e-bdef-40393b2670b0",
   "metadata": {},
   "source": [
    "https://www.analyticsvidhya.com/blog/2018/06/comprehensive-guide-for-ensemble-models/#4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5835ea3b-8c26-4bdb-b87a-3562c3353860",
   "metadata": {},
   "source": [
    "https://towardsdatascience.com/having-an-imbalanced-dataset-here-is-how-you-can-solve-it-1640568947eb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed720840-9e21-43fb-8fc5-0777bcfebe9a",
   "metadata": {},
   "source": [
    "https://neptune.ai/blog/cross-validation-mistakes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9c7e1be-5ddd-4911-9a86-03519a5e0df4",
   "metadata": {},
   "source": [
    "# 1. Import libraries, methods, and data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7c9eaeb-a2e6-47d0-a7c0-886d00fbe0c6",
   "metadata": {},
   "source": [
    "## 1.1. Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d7304b8d-d3fb-4a48-b6fd-6e9b239a0e80",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Data wrangling\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy.random import uniform, normal, seed\n",
    "\n",
    "# Machine learning\n",
    "import sklearn\n",
    "from sklearn import svm\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from imblearn.ensemble import BalancedBaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, ConfusionMatrixDisplay, roc_auc_score, balanced_accuracy_score\n",
    "from sklearn.model_selection import RepeatedKFold, RepeatedStratifiedKFold, RandomizedSearchCV, GridSearchCV, train_test_split\n",
    "import scipy\n",
    "from scipy.stats import randint\n",
    "import xgboost as xgb\n",
    "from imblearn.over_sampling import SMOTENC, RandomOverSampler, SMOTE\n",
    "from imblearn.under_sampling import TomekLinks, NeighbourhoodCleaningRule, EditedNearestNeighbours, RandomUnderSampler\n",
    "from imblearn.combine import SMOTEENN, SMOTETomek\n",
    "import optuna\n",
    "\n",
    "# Tree Visualisation\n",
    "from sklearn.tree import export_graphviz\n",
    "from IPython.display import Image\n",
    "import graphviz\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns # for kernel density plots\n",
    "\n",
    "# for nested dictionary\n",
    "import collections\n",
    "def makehash():\n",
    "    return collections.defaultdict(makehash)\n",
    "\n",
    "# Fairness\n",
    "import aif360\n",
    "import fairlearn\n",
    "from fairlearn.metrics import demographic_parity_difference, demographic_parity_ratio, equalized_odds_difference, equalized_odds_ratio, false_negative_rate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17ff3d45-316d-49f4-a8b4-75b4e47d6281",
   "metadata": {},
   "source": [
    "The __demographic parity difference__ of 0 means that all groups have the same selection rate. For multiple groups, average across all pairwise differences. Ranges between 0 and 1.\n",
    "\n",
    "The __demographic parity ratio__ of 1 means that all groups have the same selection rate.\n",
    "\n",
    "The __equalized odds difference__ of 0 means that all groups have the same true positive, true negative, false positive, and false negative rates.\n",
    "\n",
    "The __equalized odds ratio__ of 1 means that all groups have the same true positive, true negative, false positive, and false negative rates."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "282ff032-c721-4d7f-8987-17837b27eb67",
   "metadata": {},
   "source": [
    "## 1.2 Reweighing Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "af0268d1-547f-41cb-b0b6-5ee1b2ab1c95",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def calc_weights(df, sens_features_name, outcome_name):\n",
    "    ''' Calculate sample weights according to calculationg given in \n",
    "           F. Kamiran and T. Calders,  \"Data Preprocessing Techniques for\n",
    "           Classification without Discrimination,\" Knowledge and Information\n",
    "           Systems, 2012.\n",
    "    ''' \n",
    "    \n",
    "    # combination of label and groups (outputs a table)\n",
    "    sens_features = df[sens_features_name]\n",
    "    outcome = df[outcome_name]\n",
    "    tab = pd.DataFrame(pd.crosstab(index=sens_features, columns=outcome))\n",
    "\n",
    "    # reweighing weights\n",
    "    w = makehash()\n",
    "    n = len(df)\n",
    "    for r in tab.index:\n",
    "        key1 = str(r)\n",
    "        row_sum = tab.loc[r].sum(axis=0)\n",
    "        for c in tab.columns:\n",
    "            key2 = str(c)\n",
    "            col_sum = tab[c].sum()\n",
    "            if tab.loc[r,c] == 0:\n",
    "                n_combo = 1\n",
    "            else:\n",
    "                n_combo = tab.loc[r,c]\n",
    "            val = (row_sum*col_sum)/(n*n_combo)\n",
    "            w[key1][key2] = val\n",
    "    \n",
    "    # Instance weights\n",
    "    instance_weights = []\n",
    "    for index, row in df.iterrows():\n",
    "        race = row[sens_features_name]\n",
    "        out = row[outcome_name]\n",
    "        instance_weights.append(w[race][str(out)])\n",
    "\n",
    "    return instance_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "00cd2dbf-90a8-41c1-9d3c-9be1005f0827",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def display_performance(X_train, y_train, X_test, y_test, model):\n",
    "    # Train performance\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    print(\"Train Accuracy:\", np.round(accuracy_score(y_train, y_train_pred),5))\n",
    "    print(\"Train Balanced Acc:\",np.round(sklearn.metrics.balanced_accuracy_score(y_train, y_train_pred),5))\n",
    "    cm = confusion_matrix(y_train, y_train_pred)\n",
    "    print(\"Train Confusion Matrix:\")\n",
    "    print(cm)\n",
    "    ConfusionMatrixDisplay(confusion_matrix=cm).plot(cmap=plt.cm.Greens);\n",
    "\n",
    "    print(\"\")\n",
    "\n",
    "    # Test performance\n",
    "    y_pred = model.predict(X_test)\n",
    "    test_accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(\"Test Accuracy:\", np.round(test_accuracy,5))\n",
    "    print(\"Test Balanced Acc:\",np.round(sklearn.metrics.balanced_accuracy_score(y_test, y_pred),5))\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    print(\"Test Confusion Matrix:\")\n",
    "    print(cm)\n",
    "    ConfusionMatrixDisplay(confusion_matrix=cm).plot(cmap=plt.cm.Greens);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "733e5255-003f-4148-9f69-9840a685a869",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def optim_thresh(X_test, y_test, model):\n",
    "    # Find optimal threshold\n",
    "    step_factor = 0.05 \n",
    "    threshold_value = 0.05\n",
    "    roc_score=0\n",
    "    predicted_proba = model.predict_proba(X_test) #probability of prediction\n",
    "    while threshold_value <=0.8: #continue to check best threshold upto probability 0.8\n",
    "        temp_thresh = threshold_value\n",
    "        predicted = (predicted_proba [:,1] >= temp_thresh).astype('int') #change the class boundary for prediction\n",
    "        if roc_score<roc_auc_score(y_test, predicted, multi_class='ovo'): #store the threshold for best classification\n",
    "            roc_score = roc_auc_score(y_test, predicted)\n",
    "            thrsh_score = threshold_value\n",
    "        threshold_value = threshold_value + step_factor\n",
    "    print('---Optimum Threshold ---',np.round(thrsh_score,5),'--ROC--',np.round(roc_score,5))\n",
    "\n",
    "    optim_thresh = thrsh_score\n",
    "    y_pred_optim = (predicted_proba [:,1] >= optim_thresh).astype('int')\n",
    "    print(\"Optimal Test Accuracy:\",np.round(accuracy_score(y_test, y_pred_optim),5))\n",
    "    print(\"Optimal Test Balanced Accuracy:\",np.round(balanced_accuracy_score(y_test, y_pred_optim),5))\n",
    "    print(\"Optimal Test AUC:\",np.round(sklearn.metrics.roc_auc_score(y_test, y_pred_optim, multi_class='ovo'),5))\n",
    "\n",
    "    # Create the confusion matrix\n",
    "    cm = confusion_matrix(y_test, y_pred_optim)\n",
    "    print(\"Test Confusion Matrix w/ Optimal Threshold:\")\n",
    "    print(cm)\n",
    "    ConfusionMatrixDisplay(confusion_matrix=cm).plot(cmap=plt.cm.Greens);\n",
    "    \n",
    "    return thrsh_score\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7740d2e8-af9c-4f91-b08f-49e073dc00de",
   "metadata": {},
   "source": [
    "## 1.3. Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e1d5158d-a1e7-44ee-bc96-83872a364881",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "all_data = pd.read_excel(\"Eynav cleaned data.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "607ce40b-628e-42e4-95a2-82f49376b787",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(all_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e53910fe-0ef3-42c7-93c3-90c410ef18c4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(all_data.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9389191c-0572-464d-95ec-8a993d2d4f0d",
   "metadata": {},
   "source": [
    "This below chuck is only for reporting demographic information in manuscript:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd1443fd-ae14-448b-a3c7-128e8120f12e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "demo = all_data[['MOM_AGE','MOM_RACE','ETHNIC_GROUP','ZIP','MARITAL_STATUS','FINANCIAL_CLASS',\n",
    "                 'LBW','PTB',\n",
    "                 'DELIVERY_METHOD','NICU_ADMIT','MFCU_ADMIT',\n",
    "                 'PREE','GDM','GHTN',\n",
    "                 'MOM_BMI','MOM_LOS','CHILD_LOS',\n",
    "                 'HIST_ANXIETY','HIST_DEPRESS','HIST_BIPOLAR','HIST_PMAD','MENTAL_HEALTH_DX_CUTOFF',\n",
    "                 'MED_PSYCH','MED_CARDIO','PMAD_risk']]\n",
    "demo = demo.dropna()            # keep only complete data (for now)\n",
    "demo = demo.sample(len(demo))   # randomly shuffle rows\n",
    "demo.shape\n",
    "\n",
    "print(\"Min Age:\",min(demo['MOM_AGE']))\n",
    "print(\"Max Age:\",max(demo['MOM_AGE']))\n",
    "print(\"Mean Age:\",np.mean(demo['MOM_AGE']))\n",
    "print(\"SD Age:\",np.std(demo['MOM_AGE']))\n",
    "\n",
    "print(\"------------RACE/ETHNIC COUNTS------------\")\n",
    "race = demo['MOM_RACE']\n",
    "ethnic = demo['ETHNIC_GROUP']\n",
    "print(pd.DataFrame(pd.crosstab(index=race, columns=ethnic)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dfc35f3-2931-45f6-8499-b05de46d7434",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(demo.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2494bda8-7fdf-4c2d-b9c8-451dfbb09346",
   "metadata": {},
   "source": [
    "Extract relevant variables for model fitting:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c280642-2dc3-4604-8a08-5593f4ea733a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "outcome = 'PHQ9_risk2'\n",
    "\n",
    "data = all_data[['MOM_AGE','MOM_RACE','ETHNIC_GROUP','ZIP','MARITAL_STATUS','FINANCIAL_CLASS',\n",
    "                 'LBW','PTB',\n",
    "                 'DELIVERY_METHOD','NICU_ADMIT','MFCU_ADMIT',\n",
    "                 'PREE','GDM','GHTN',\n",
    "                 'MOM_BMI','MOM_LOS','CHILD_LOS',\n",
    "                 'HIST_ANXIETY','HIST_DEPRESS','HIST_BIPOLAR','HIST_PMAD','MENTAL_HEALTH_DX_CUTOFF',\n",
    "                 'MED_PSYCH','MED_CARDIO',\n",
    "                 outcome,'PHQ9_VALUE']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5ddfc81-a213-4077-a476-a9133b941b89",
   "metadata": {},
   "source": [
    "## 1.3.3. Curate Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beb2829b-4b79-4540-9de3-963432722234",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = data.dropna()            # keep only complete data (for now)\n",
    "data = data.sample(len(data))   # randomly shuffle rows\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee0d018f-afc1-4664-bed8-9fca41eee492",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "scale_data = data[['MOM_RACE','ETHNIC_GROUP','PHQ9_VALUE','PHQ9_risk2']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "430ebd14-5746-4562-b856-90c9f2982b83",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "scale_data2 = scale_data[scale_data.PHQ9_risk2==1]\n",
    "\n",
    "# create a grid \n",
    "g = sns.FacetGrid(scale_data2, col='MOM_RACE', hue='MOM_RACE', col_wrap=3)\n",
    "\n",
    "# draw density plots\n",
    "g = g.map(sns.kdeplot,\"PHQ9_VALUE\", cut=0, fill=True, common_norm=False, alpha=1, legend=False)\n",
    "\n",
    "# control the title of each facet\n",
    "g = g.set_titles(\"{col_name}\")\n",
    "\n",
    "# show the graph\n",
    "#plt.show()\n",
    "\n",
    "plt.savefig('Figure 1.png',dpi=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "000904b0-e29e-4f9a-84e1-cf945a5c99d8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = data.drop(['PHQ9_VALUE'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec555ea8-fc33-4e73-b6d6-fb4cdfbef1d4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "race = data['MOM_RACE']\n",
    "ethnic = data['ETHNIC_GROUP']\n",
    "out = data[outcome]\n",
    "\n",
    "print(\"------------MEDIAN AGE------------\")\n",
    "print(pd.crosstab(index=race, columns=ethnic, values=data['MOM_AGE'], aggfunc=np.median))\n",
    "print(\"Overall median age:\",np.median(data[['MOM_AGE']]))\n",
    "\n",
    "print(\"------------RACE/ETHNIC COUNTS------------\")\n",
    "print(pd.DataFrame(pd.crosstab(index=race, columns=ethnic)))\n",
    "\n",
    "print(\"------------RACE/ETHNIC PMAD------------\")\n",
    "print(pd.crosstab(index=[ethnic,race], columns=out, normalize='index'))\n",
    "\n",
    "print(\"Overall PMAD:\",np.mean(data[[outcome]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff0ed39c-8fcc-4e4a-9815-3fadb112d65b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# binary-class\n",
    "count0, count1 = data[outcome].value_counts()\n",
    "print(count0, count1)\n",
    "\n",
    "x = ['0','1']\n",
    "y = [count0, count1]\n",
    "plt.bar(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8ae4e6a-4a24-469c-82d6-1b78cdfdf199",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"N:\",data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb70876a-2439-4feb-9eb7-80b3b5c42705",
   "metadata": {},
   "source": [
    "## 1.3.4. Weight Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c9edb6a-ac6a-4fce-a630-3aa184c70f1e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data['w'] = calc_weights(df=data, sens_features_name=\"MOM_RACE\", outcome_name=outcome)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fa1c247-a3ed-4aae-a605-1157ff4dccf7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data[['w',outcome,'MOM_RACE']].drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ef39be7-18ca-4472-8d60-94e27e1bf103",
   "metadata": {},
   "source": [
    "## 1.3.5. Get Dummies and Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a59f1b66-2d4d-4946-beb2-84c5cf66cd51",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# get dummy variables\n",
    "data = pd.get_dummies(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c295f69-bf12-45c5-a695-9f82d7d7e68f",
   "metadata": {},
   "source": [
    "Split data. Can specify whether to use stratify sampling or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac1776d1-d791-442e-8088-df078e882ced",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# split into X and y\n",
    "X = data.drop([outcome], axis=1)\n",
    "y = data[[outcome]]\n",
    "\n",
    "race = data[['MOM_RACE_Asian or Native Hawaiian or Other Pacific Islander',\n",
    "             'MOM_RACE_Black or African American',\n",
    "             'MOM_RACE_Multiracial',\n",
    "             'MOM_RACE_Other',\n",
    "             'MOM_RACE_Unknown',\n",
    "             'MOM_RACE_White',\n",
    "             'MOM_RACE_Hispanic White']]\n",
    "strat_df = pd.concat([y,race],axis=1)\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.85, test_size=0.15, shuffle=True, stratify=strat_df, random_state=0)\n",
    "X_test = X_test.drop(['w'], axis=1)\n",
    "\n",
    "# Sensitive features\n",
    "race_feature = X_test[['MOM_RACE_Asian or Native Hawaiian or Other Pacific Islander',\n",
    "                       'MOM_RACE_Black or African American',\n",
    "                       'MOM_RACE_Multiracial',\n",
    "                       'MOM_RACE_Other',\n",
    "                       'MOM_RACE_Unknown',\n",
    "                       'MOM_RACE_White',\n",
    "                       'MOM_RACE_Hispanic White']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74342e39-7fdf-40c0-b13e-47b4f54cc4bc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# binary-class\n",
    "count0_train, count1_train = y_train.value_counts()\n",
    "print(count0_train, count1_train)\n",
    "\n",
    "count0_test, count1_test = y_test.value_counts()\n",
    "print(count0_test, count1_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61a8b3da-bc5e-47a4-bce5-8436efc39b41",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c8279fc-a583-4003-8370-3156c6b3e51b",
   "metadata": {},
   "source": [
    "# 2. Handle imbalanced data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffcdb97c-9131-4b4e-9a9a-e1682a12f6fd",
   "metadata": {},
   "source": [
    "## 2.1. Simple Over Sampling Minority (PMAD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "087ff68c-19b5-4347-b37d-3d188d7880d8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ros = RandomOverSampler(sampling_strategy = \"auto\",random_state=0)\n",
    "X_train_ros, y_train_ros = ros.fit_resample(X_train, y_train)\n",
    "weights_ros = X_train_ros['w']\n",
    "X_train_ros = X_train_ros.drop(['w'], axis=1)\n",
    "y_train_ros.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdf9eeca-143a-43ef-8267-f856033ef710",
   "metadata": {},
   "source": [
    "## 2.2. Simple Under Sampling Majority (PMAD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18ec6feb-0165-4b67-bc17-ce847624fc26",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "rus = RandomUnderSampler(sampling_strategy = \"auto\", random_state=0)\n",
    "X_train_rus, y_train_rus = rus.fit_resample(X_train, y_train)\n",
    "weights_rus = X_train_rus['w']\n",
    "X_train_rus = X_train_rus.drop(['w'], axis=1)\n",
    "y_train_rus.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b7b0d9a-4526-450f-b818-801ee4c46dd3",
   "metadata": {},
   "source": [
    "# 3. Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0436c426-f293-4bc8-9fae-889ec3613e65",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Extract weights and drop from training and test data frames\n",
    "weights = X_train['w']\n",
    "X_train = X_train.drop(['w'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fac9c47f-2b83-48f2-ba50-df573f21a4fb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Base group is non-Hispanic White\n",
    "races = ['MOM_RACE_Asian or Native Hawaiian or Other Pacific Islander',\n",
    "         'MOM_RACE_Black or African American',\n",
    "         'MOM_RACE_Hispanic White',\n",
    "         'MOM_RACE_Multiracial',\n",
    "         'MOM_RACE_Other',\n",
    "         'MOM_RACE_Unknown']\n",
    "\n",
    "reweigh_results = []\n",
    "no_reweigh_results = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd54706e-b6e2-4c46-adc5-84a94eb2a1a6",
   "metadata": {},
   "source": [
    "## XG Boost Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcab2af6-5d71-4ca2-929a-3f740c5ef5a8",
   "metadata": {},
   "source": [
    "https://www.kaggle.com/code/stuarthallows/using-xgboost-with-scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "865b3363-29ce-458e-87f2-5fb17f99123b",
   "metadata": {},
   "source": [
    "### Finetune XG Boost Classifier without Reweighing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b308cbc3-7dce-4a92-a329-b9441edd64a2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x = X_train_rus\n",
    "y = y_train_rus.values.ravel()\n",
    "\n",
    "def objective(trial):\n",
    "    params = {\n",
    "        \"seed\":0,\n",
    "        \"objective\": \"binary:hinge\",\n",
    "        \"n_estimators\": 1000,\n",
    "        \"verbosity\": 0,\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 1e-3, 0.1, log=True),\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 1, 10),\n",
    "        \"subsample\": trial.suggest_float(\"subsample\", 0.05, 1.0),\n",
    "        \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.05, 1.0),\n",
    "        \"min_child_weight\": trial.suggest_int(\"min_child_weight\", 1, 20),\n",
    "    }\n",
    "\n",
    "    model = xgb.XGBClassifier(**params,random_state=0)\n",
    "    model.fit(x, y, verbose=False)\n",
    "    predictions = model.predict(X_test)\n",
    "    BA = balanced_accuracy_score(y_test, predictions)\n",
    "    return BA\n",
    "\n",
    "#optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
    "sampler = optuna.samplers.TPESampler(seed=0) \n",
    "study = optuna.create_study(direction='maximize',sampler=sampler)\n",
    "study.optimize(objective, n_trials=250)\n",
    "\n",
    "best_xgb = xgb.XGBClassifier(objective='binary:hinge',n_estimators=1000, verbosity=0, seed=0, **study.best_params)\n",
    "best_xgb.fit(x,y,verbose=False)\n",
    "y_pred = best_xgb.predict(X_test)\n",
    "test_balanced_acc = sklearn.metrics.balanced_accuracy_score(y_test,y_pred)\n",
    "print('Test Balanced Accuracy:', np.round(test_balanced_acc,3))\n",
    "\n",
    "optim_threshold = optim_thresh(X_test=X_test, y_test=y_test, model=best_xgb)\n",
    "y_pred_optim = pd.DataFrame((best_xgb.predict_proba(X_test)[:,1] >= optim_threshold).astype('int'),columns=['y_pred'])\n",
    "\n",
    "test_set = pd.concat([y_pred_optim,y_test.reset_index(drop=True),X_test.reset_index(drop=True)],axis=1)\n",
    "\n",
    "# Demographic parity\n",
    "p_white = np.mean(test_set['y_pred'][test_set['MOM_RACE_White']==1])\n",
    "\n",
    "# TP and FN\n",
    "pos_lab_set_white = test_set[(test_set[outcome]==1) & (test_set['MOM_RACE_White']==1)]\n",
    "pos_lab_set_white['fn'] = np.where(pos_lab_set_white['y_pred']==0,1,0)\n",
    "fn_white = np.mean(pos_lab_set_white['fn'])\n",
    "pos_lab_set_white['tp'] = np.where(pos_lab_set_white['y_pred']==1,1,0)\n",
    "tp_white = np.mean(pos_lab_set_white['tp'])\n",
    "\n",
    "for r in races:\n",
    "    pos_lab = test_set[(test_set[outcome]==1) & (test_set[r]==1)]\n",
    "    pos_lab['fn'] = np.where(pos_lab['y_pred']==0,1,0)\n",
    "    pos_lab['tp'] = np.where(pos_lab['y_pred']==1,1,0)\n",
    "    no_reweigh_results.append({'Model':'XGB',\n",
    "                               'Race': r,\n",
    "                               'DP':np.mean(test_set['y_pred'][test_set[r]==1])-p_white,\n",
    "                               'FN':np.mean(pos_lab['fn'])-fn_white,\n",
    "                               'TP':np.mean(pos_lab['tp'])-tp_white})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea1bbcdf-a71e-4228-b0c7-46c635ed049e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import joblib\n",
    "joblib.dump(best_xgb, 'best_xgb_phq9_no_reweigh.pkl') \n",
    "\n",
    "# to use later:\n",
    "#best_glm_phq9_no_reweigh = joblib.load('best_xgb_phq9_no_reweigh.pkl') \n",
    "#best_glm_phq9_no_reweigh.predict([[300,85,5,5,5,8,1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec27e1eb-0c3b-4bf4-bb55-e7cf776a828b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "optim_threshold = optim_thresh(X_test=X_test, y_test=y_test, model=best_xgb)\n",
    "y_pred_optim = pd.DataFrame((best_xgb.predict_proba(X_test)[:,1] >= optim_threshold).astype('int'),columns=['y_pred'])\n",
    "\n",
    "print('AUCROC:',roc_auc_score(y_test,y_pred_optim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22a69c09-e1ef-420e-b862-3e454b63208d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "gain = best_xgb.get_booster().get_score(importance_type='gain')\n",
    "gain_sorted = dict(sorted(gain.items(), key=lambda x: x[1], reverse=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3235d0ce-54d1-4e1b-a9b4-2be58f88beaf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "features = list(gain_sorted.keys())\n",
    "values = list(gain_sorted.values())\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.barh(features,values)\n",
    "plt.yticks(fontsize=5.5)\n",
    "ax.set_xlabel(\"Gain\")\n",
    "plt.savefig('PHQ-9 XGB Feature Importance.png',dpi=600, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93f7064c-d970-4f54-ba83-e4688fa923fa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(no_reweigh_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "456163af-7dcd-4173-94a4-09acea9f4b8d",
   "metadata": {},
   "source": [
    "### Finetune XG Boost Classifier with Reweighing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47e98efb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x = X_train_rus\n",
    "y = y_train_rus.values.ravel()\n",
    "w = weights_rus\n",
    "\n",
    "def objective(trial):\n",
    "    params = {\n",
    "        \"seed\":0,\n",
    "        \"objective\": \"binary:hinge\",\n",
    "        \"n_estimators\": 1000,\n",
    "        \"verbosity\": 0,\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 1e-3, 0.1, log=True),\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 1, 10),\n",
    "        \"subsample\": trial.suggest_float(\"subsample\", 0.05, 1.0),\n",
    "        \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.05, 1.0),\n",
    "        \"min_child_weight\": trial.suggest_int(\"min_child_weight\", 1, 20),\n",
    "    }\n",
    "\n",
    "    model = xgb.XGBClassifier(**params)\n",
    "    model.fit(x, y, sample_weight=w, verbose=False)\n",
    "    predictions = model.predict(X_test)\n",
    "    BA = balanced_accuracy_score(y_test, predictions)\n",
    "    return BA\n",
    "\n",
    "#optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
    "sampler = optuna.samplers.TPESampler(seed=0) \n",
    "study = optuna.create_study(direction='maximize',sampler=sampler)\n",
    "study.optimize(objective, n_trials=250)\n",
    "\n",
    "best_xgb2 = xgb.XGBClassifier(objective='binary:hinge',n_estimators=1000, verbosity=0, seed=0, **study.best_params)\n",
    "best_xgb2.fit(x,y,sample_weight=w,verbose=False)\n",
    "y_pred = best_xgb2.predict(X_test)\n",
    "test_balanced_acc = sklearn.metrics.balanced_accuracy_score(y_test,y_pred)\n",
    "print('Test Balanced Accuracy:', np.round(test_balanced_acc,3))\n",
    "\n",
    "optim_threshold = optim_thresh(X_test=X_test, y_test=y_test, model=best_xgb2)\n",
    "y_pred_optim = pd.DataFrame((best_xgb2.predict_proba(X_test)[:,1] >= optim_threshold).astype('int'),columns=['y_pred'])\n",
    "\n",
    "test_set = pd.concat([y_pred_optim,y_test.reset_index(drop=True),X_test.reset_index(drop=True)],axis=1)\n",
    "\n",
    "# Demographic parity\n",
    "p_white = np.mean(test_set['y_pred'][test_set['MOM_RACE_White']==1])\n",
    "\n",
    "# TP and FN\n",
    "pos_lab_set_white = test_set[(test_set[outcome]==1) & (test_set['MOM_RACE_White']==1)]\n",
    "pos_lab_set_white['fn'] = np.where(pos_lab_set_white['y_pred']==0,1,0)\n",
    "fn_white = np.mean(pos_lab_set_white['fn'])\n",
    "pos_lab_set_white['tp'] = np.where(pos_lab_set_white['y_pred']==1,1,0)\n",
    "tp_white = np.mean(pos_lab_set_white['tp'])\n",
    "\n",
    "for r in races:\n",
    "    pos_lab = test_set[(test_set[outcome]==1) & (test_set[r]==1)]\n",
    "    pos_lab['fn'] = np.where(pos_lab['y_pred']==0,1,0)\n",
    "    pos_lab['tp'] = np.where(pos_lab['y_pred']==1,1,0)\n",
    "    reweigh_results.append({'Model':'XGB',\n",
    "                               'Race': r,\n",
    "                               'DP':np.mean(test_set['y_pred'][test_set[r]==1])-p_white,\n",
    "                               'FN':np.mean(pos_lab['fn'])-fn_white,\n",
    "                               'TP':np.mean(pos_lab['tp'])-tp_white})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a465a11c-6b1d-4793-b3c0-c93948c2c6e6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "joblib.dump(best_xgb2, 'best_xgb_phq9_reweigh.pkl') \n",
    "\n",
    "# to use later:\n",
    "#best_xgb_phq9_reweigh = joblib.load('best_xgb_phq9_reweigh.pkl') \n",
    "#best_xgb_phq9_reweigh.predict([[300,85,5,5,5,8,1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3e1c1aa-2aa0-4034-83a5-edc7bc58ae26",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "gain = best_xgb2.get_booster().get_score(importance_type='gain')\n",
    "gain_sorted = dict(sorted(gain.items(), key=lambda x: x[1], reverse=False))\n",
    "\n",
    "features = list(gain_sorted.keys())\n",
    "values = list(gain_sorted.values())\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.barh(features,values)\n",
    "plt.yticks(fontsize=5.5)\n",
    "ax.set_xlabel(\"Gain\")\n",
    "plt.savefig('PHQ-9 XGB Feature Importance Reweigh.png',dpi=600, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83357ed0-da77-44aa-9f60-eeb2486859d4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(reweigh_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05801c3f-dc88-4e80-b6c3-00dcce6cffa9",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ece2000-9b22-4aa5-be54-30f5146c7d94",
   "metadata": {},
   "source": [
    "### Finetune Random Forest without Reweighing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0c1b873-e142-4eb2-b121-22b833fa4e01",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x = X_train_rus\n",
    "y = y_train_rus.values.ravel()\n",
    "\n",
    "def objective(trial):\n",
    "    params = {'random_state':trial.suggest_int('random_state', 0, 50),\n",
    "             'max_features':'sqrt',\n",
    "             'min_samples_leaf': trial.suggest_int('min_samples_leaf', 1, 50),\n",
    "             'min_samples_split': trial.suggest_int('min_samples_split', 2, 50),\n",
    "             'n_estimators': trial.suggest_int('n_estimators', 2, 20),\n",
    "             'max_depth': trial.suggest_int('max_depth', 1, 32)\n",
    "             }\n",
    "    model = RandomForestClassifier(**params)\n",
    "    model.fit(x, y)\n",
    "    predictions = model.predict(X_test)\n",
    "    BA = balanced_accuracy_score(y_test, predictions)\n",
    "    return BA\n",
    "\n",
    "sampler = optuna.samplers.TPESampler(seed=0) \n",
    "study = optuna.create_study(direction='maximize',sampler=sampler)\n",
    "study.optimize(objective, n_trials=250)\n",
    "\n",
    "print('Best hyperparameters:', study.best_params)\n",
    "print('Best Balanced Accuracy:', study.best_value)\n",
    "\n",
    "best_rf = RandomForestClassifier(max_features='sqrt',**study.best_params)\n",
    "best_rf.fit(x,y)\n",
    "y_pred = best_rf.predict(X_test)\n",
    "test_balanced_acc = sklearn.metrics.balanced_accuracy_score(y_test,y_pred)\n",
    "print('Test Balanced Accuracy:', np.round(test_balanced_acc,3))\n",
    "\n",
    "optim_threshold = optim_thresh(X_test=X_test, y_test=y_test, model=best_rf)\n",
    "y_pred_optim = pd.DataFrame((best_rf.predict_proba(X_test)[:,1] >= optim_threshold).astype('int'),columns=['y_pred'])\n",
    "test_set = pd.concat([pd.DataFrame(y_pred_optim),y_test.reset_index(drop=True),X_test.reset_index(drop=True)],axis=1)\n",
    "\n",
    "# Demographic parity\n",
    "p_white = np.mean(test_set['y_pred'][test_set['MOM_RACE_White']==1])\n",
    "\n",
    "# Equalized odds\n",
    "pos_lab_set_white = test_set[(test_set[outcome]==1) & (test_set['MOM_RACE_White']==1)]\n",
    "pos_lab_set_white['fn'] = np.where(pos_lab_set_white['y_pred']==0,1,0)\n",
    "fn_white = np.mean(pos_lab_set_white['fn'])\n",
    "pos_lab_set_white['tp'] = np.where(pos_lab_set_white['y_pred']==1,1,0)\n",
    "tp_white = np.mean(pos_lab_set_white['tp'])\n",
    "\n",
    "for r in races:\n",
    "    pos_lab = test_set[(test_set[outcome]==1) & (test_set[r]==1)]\n",
    "    pos_lab['fn'] = np.where(pos_lab['y_pred']==0,1,0)\n",
    "    pos_lab['tp'] = np.where(pos_lab['y_pred']==1,1,0)\n",
    "    no_reweigh_results.append({'Model':'RF',\n",
    "                               'Race': r,\n",
    "                               'DP':np.mean(test_set['y_pred'][test_set[r]==1])-p_white,\n",
    "                               'FN':np.mean(pos_lab['fn'])-fn_white,\n",
    "                               'TP':np.mean(pos_lab['tp'])-tp_white})\n",
    "    \n",
    "print('AUCROC:',roc_auc_score(y_test,y_pred_optim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb15c5bf-eeb2-4541-915b-a0d8df6f68de",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "joblib.dump(best_rf, 'best_rf_phq9_no_reweigh.pkl') \n",
    "\n",
    "# to use later:\n",
    "#best_rf_phq9_no_reweigh = joblib.load('best_rf_phq9_no_reweigh.pkl') \n",
    "#best_rf_phq9_no_reweigh.predict([[300,85,5,5,5,8,1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5857b780-ebdf-405b-b6b0-193e6d60ee13",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.inspection import permutation_importance\n",
    "result = permutation_importance(\n",
    "    best_rf, X_test, y_test, n_repeats=10, random_state=2024, n_jobs=2\n",
    ")\n",
    "\n",
    "importance_mean = result.importances_mean\n",
    "importance_sd = result.importances_std\n",
    "\n",
    "ind = np.argpartition(importance_mean, -10)[-10:]\n",
    "top_feat = X_test.columns[ind]\n",
    "top_vals = importance_mean[ind]\n",
    "top_std = importance_sd[ind]\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.barh(top_feat,top_vals,xerr=top_std)\n",
    "ax.set_xlabel(\"Mean accuracy decrease\")\n",
    "plt.savefig('PHQ-9 RF Feature Importance.png',dpi=600, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1827b0c-58af-4582-8b92-112cf6b5151b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(no_reweigh_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "632da262-e2de-44fa-8c05-9dd292f87f2f",
   "metadata": {},
   "source": [
    "### Finetune Random Forest with Reweighing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9e54b26-8ee9-4208-bf7e-1c534619841e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x = X_train_rus\n",
    "y = y_train_rus.values.ravel()\n",
    "w = weights_rus\n",
    "\n",
    "def objective(trial):\n",
    "    params = {'random_state':trial.suggest_int('random_state', 0, 50),\n",
    "             'max_features':'sqrt',\n",
    "             'min_samples_leaf': trial.suggest_int('min_samples_leaf', 1, 50),\n",
    "             'min_samples_split': trial.suggest_int('min_samples_split', 2, 50),\n",
    "             'n_estimators': trial.suggest_int('n_estimators', 2, 20),\n",
    "             'max_depth': trial.suggest_int('max_depth', 1, 32)\n",
    "             }\n",
    "    model = RandomForestClassifier(**params)\n",
    "    model.fit(x, y, sample_weight=w)\n",
    "    predictions = model.predict(X_test)\n",
    "    BA = balanced_accuracy_score(y_test, predictions)\n",
    "    return BA\n",
    "\n",
    "sampler = optuna.samplers.TPESampler(seed=0) \n",
    "study = optuna.create_study(direction='maximize',sampler=sampler)\n",
    "study.optimize(objective, n_trials=250)\n",
    "\n",
    "print('Best hyperparameters:', study.best_params)\n",
    "print('Best Balanced Accuracy:', study.best_value)\n",
    "\n",
    "best_rf = RandomForestClassifier(max_features='sqrt',**study.best_params)\n",
    "best_rf.fit(x,y,sample_weight=w)\n",
    "y_pred = best_rf.predict(X_test)\n",
    "test_balanced_acc = sklearn.metrics.balanced_accuracy_score(y_test,y_pred)\n",
    "print('Test Balanced Accuracy:', np.round(test_balanced_acc,3))\n",
    "\n",
    "optim_threshold = optim_thresh(X_test=X_test, y_test=y_test, model=best_rf)\n",
    "y_pred_optim = pd.DataFrame((best_rf.predict_proba(X_test)[:,1] >= optim_threshold).astype('int'),columns=['y_pred'])\n",
    "test_set = pd.concat([pd.DataFrame(y_pred_optim),y_test.reset_index(drop=True),X_test.reset_index(drop=True)],axis=1)\n",
    "\n",
    "# Demographic parity\n",
    "p_white = np.mean(test_set['y_pred'][test_set['MOM_RACE_White']==1])\n",
    "\n",
    "# Equalized odds\n",
    "pos_lab_set_white = test_set[(test_set[outcome]==1) & (test_set['MOM_RACE_White']==1)]\n",
    "pos_lab_set_white['fn'] = np.where(pos_lab_set_white['y_pred']==0,1,0)\n",
    "fn_white = np.mean(pos_lab_set_white['fn'])\n",
    "pos_lab_set_white['tp'] = np.where(pos_lab_set_white['y_pred']==1,1,0)\n",
    "tp_white = np.mean(pos_lab_set_white['tp'])\n",
    "\n",
    "for r in races:\n",
    "    pos_lab = test_set[(test_set[outcome]==1) & (test_set[r]==1)]\n",
    "    pos_lab['fn'] = np.where(pos_lab['y_pred']==0,1,0)\n",
    "    pos_lab['tp'] = np.where(pos_lab['y_pred']==1,1,0)\n",
    "    reweigh_results.append({'Model':'RF',\n",
    "                               'Race': r,\n",
    "                               'DP':np.mean(test_set['y_pred'][test_set[r]==1])-p_white,\n",
    "                               'FN':np.mean(pos_lab['fn'])-fn_white,\n",
    "                               'TP':np.mean(pos_lab['tp'])-tp_white})\n",
    "print('AUCROC:',roc_auc_score(y_test,y_pred_optim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a3b2450-2715-4713-81cf-d3ddf5b030e9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "joblib.dump(best_rf, 'best_rf_phq9_reweigh.pkl') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8897fc69-4fd0-4998-87d9-56d561559f1a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.inspection import permutation_importance\n",
    "result = permutation_importance(\n",
    "    best_rf, X_test, y_test, n_repeats=10, random_state=2024, n_jobs=2\n",
    ")\n",
    "\n",
    "importance_mean = result.importances_mean\n",
    "importance_sd = result.importances_std\n",
    "\n",
    "ind = np.argpartition(importance_mean, -10)[-10:]\n",
    "top_feat = X_test.columns[ind]\n",
    "top_vals = importance_mean[ind]\n",
    "top_std = importance_sd[ind]\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.barh(top_feat,top_vals,xerr=top_std)\n",
    "ax.set_xlabel(\"Mean accuracy decrease\")\n",
    "plt.savefig('PHQ-9 RF Feature Importance Reweigh.png',dpi=600, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec372021-43cc-4c9d-bfa3-886207a97fe4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(reweigh_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "260997ed-80f7-43a6-bdb1-47f7fd488d41",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2efa24d-dd83-42b5-ab94-e404867038d2",
   "metadata": {},
   "source": [
    "### Finetune Logistic Regression without Reweighing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e985914-ec69-47f9-ab18-4ac90c27f433",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x = X_train_rus\n",
    "y = y_train_rus.values.ravel()\n",
    "\n",
    "def objective(trial):\n",
    "    params = {'penalty':'l2',\n",
    "             'C':trial.suggest_loguniform(\"C\", 1e-2, 1),\n",
    "             'tol':trial.suggest_uniform('tol' , 1e-6 , 1e-3)\n",
    "             }\n",
    "    model = LogisticRegression(**params)\n",
    "    model.fit(x,y)\n",
    "    predictions = model.predict(X_test)\n",
    "    BA = balanced_accuracy_score(y_test, predictions)\n",
    "    return BA\n",
    "\n",
    "sampler = optuna.samplers.TPESampler(seed=0) \n",
    "study = optuna.create_study(direction='maximize',sampler=sampler)\n",
    "study.optimize(objective, n_trials=250)\n",
    "\n",
    "print('Best hyperparameters:', study.best_params)\n",
    "print('Best Balanced Accuracy:', study.best_value)\n",
    "\n",
    "best_glm = LogisticRegression(penalty='l2',**study.best_params)\n",
    "best_glm.fit(x,y)\n",
    "y_pred = best_glm.predict(X_test)\n",
    "test_balanced_acc = sklearn.metrics.balanced_accuracy_score(y_test,y_pred)\n",
    "print('Test Balanced Accuracy:', np.round(test_balanced_acc,3))\n",
    "\n",
    "optim_threshold = optim_thresh(X_test=X_test, y_test=y_test, model=best_glm)\n",
    "y_pred_optim = pd.DataFrame((best_glm.predict_proba(X_test)[:,1] >= optim_threshold).astype('int'),columns=['y_pred'])\n",
    "test_set = pd.concat([pd.DataFrame(y_pred_optim),y_test.reset_index(drop=True),X_test.reset_index(drop=True)],axis=1)\n",
    "\n",
    "# Demographic parity\n",
    "p_white = np.mean(test_set['y_pred'][test_set['MOM_RACE_White']==1])\n",
    "\n",
    "# Equalized odds\n",
    "pos_lab_set_white = test_set[(test_set[outcome]==1) & (test_set['MOM_RACE_White']==1)]\n",
    "pos_lab_set_white['fn'] = np.where(pos_lab_set_white['y_pred']==0,1,0)\n",
    "fn_white = np.mean(pos_lab_set_white['fn'])\n",
    "pos_lab_set_white['tp'] = np.where(pos_lab_set_white['y_pred']==1,1,0)\n",
    "tp_white = np.mean(pos_lab_set_white['tp'])\n",
    "\n",
    "for r in races:\n",
    "    pos_lab = test_set[(test_set[outcome]==1) & (test_set[r]==1)]\n",
    "    pos_lab['fn'] = np.where(pos_lab['y_pred']==0,1,0)\n",
    "    pos_lab['tp'] = np.where(pos_lab['y_pred']==1,1,0)\n",
    "    no_reweigh_results.append({'Model':'LR',\n",
    "                               'Race': r,\n",
    "                               'DP':np.mean(test_set['y_pred'][test_set[r]==1])-p_white,\n",
    "                               'FN':np.mean(pos_lab['fn'])-fn_white,\n",
    "                               'TP':np.mean(pos_lab['tp'])-tp_white})\n",
    "print('AUCROC:',roc_auc_score(y_test,y_pred_optim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f621369-70ef-4996-b7ff-e11d26eb8b7a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "joblib.dump(best_glm, 'best_glm_phq9_no_reweigh.pkl') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39f55346-3a93-483d-a9ad-f087a3ed4638",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(no_reweigh_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5ba107a-0f54-4d86-a80a-1a3c1f6ec58e",
   "metadata": {},
   "source": [
    "### Finetune Logistic Regression with Reweighing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c084011d-209a-40e9-af4a-33d797274f28",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x = X_train_rus\n",
    "y = y_train_rus.values.ravel()\n",
    "w = weights_rus\n",
    "\n",
    "def objective(trial):\n",
    "    params = {'penalty':'l2',\n",
    "             'C':trial.suggest_loguniform(\"C\", 1e-2, 1),\n",
    "             'tol':trial.suggest_uniform('tol' , 1e-6 , 1e-3)\n",
    "             }\n",
    "    model = LogisticRegression(**params)\n",
    "    model.fit(x, y, sample_weight=w)\n",
    "    predictions = model.predict(X_test)\n",
    "    BA = balanced_accuracy_score(y_test, predictions)\n",
    "    return BA\n",
    "\n",
    "sampler = optuna.samplers.TPESampler(seed=0) \n",
    "study = optuna.create_study(direction='maximize',sampler=sampler)\n",
    "study.optimize(objective, n_trials=250)\n",
    "\n",
    "print('Best hyperparameters:', study.best_params)\n",
    "print('Best Balanced Accuracy:', study.best_value)\n",
    "\n",
    "best_glm = LogisticRegression(penalty='l2',**study.best_params)\n",
    "best_glm.fit(x,y,sample_weight=w)\n",
    "y_pred = best_glm.predict(X_test)\n",
    "test_balanced_acc = sklearn.metrics.balanced_accuracy_score(y_test,y_pred)\n",
    "print('Test Balanced Accuracy:', np.round(test_balanced_acc,3))\n",
    "\n",
    "optim_threshold = optim_thresh(X_test=X_test, y_test=y_test, model=best_glm)\n",
    "y_pred_optim = pd.DataFrame((best_glm.predict_proba(X_test)[:,1] >= optim_threshold).astype('int'),columns=['y_pred'])\n",
    "test_set = pd.concat([pd.DataFrame(y_pred_optim),y_test.reset_index(drop=True),X_test.reset_index(drop=True)],axis=1)\n",
    "\n",
    "# Demographic parity\n",
    "p_white = np.mean(test_set['y_pred'][test_set['MOM_RACE_White']==1])\n",
    "\n",
    "# Equalized odds\n",
    "pos_lab_set_white = test_set[(test_set[outcome]==1) & (test_set['MOM_RACE_White']==1)]\n",
    "pos_lab_set_white['fn'] = np.where(pos_lab_set_white['y_pred']==0,1,0)\n",
    "fn_white = np.mean(pos_lab_set_white['fn'])\n",
    "pos_lab_set_white['tp'] = np.where(pos_lab_set_white['y_pred']==1,1,0)\n",
    "tp_white = np.mean(pos_lab_set_white['tp'])\n",
    "\n",
    "for r in races:\n",
    "    pos_lab = test_set[(test_set[outcome]==1) & (test_set[r]==1)]\n",
    "    pos_lab['fn'] = np.where(pos_lab['y_pred']==0,1,0)\n",
    "    pos_lab['tp'] = np.where(pos_lab['y_pred']==1,1,0)\n",
    "    reweigh_results.append({'Model':'LR',\n",
    "                               'Race': r,\n",
    "                               'DP':np.mean(test_set['y_pred'][test_set[r]==1])-p_white,\n",
    "                               'FN':np.mean(pos_lab['fn'])-fn_white,\n",
    "                               'TP':np.mean(pos_lab['tp'])-tp_white})\n",
    "print('AUCROC:',roc_auc_score(y_test,y_pred_optim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16bb6171-479b-421a-81d0-9c22ccf90743",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "joblib.dump(best_glm, 'best_glm_phq9_reweigh.pkl') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "423efc98-cbbd-44f4-958e-fc4190db0f32",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(reweigh_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30b7c10a-61c2-4f6e-8a9e-2063d4fac4f4",
   "metadata": {},
   "source": [
    "# Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a0e6985-6c67-4700-9463-1d3cdd726a85",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "no_reweigh_results = pd.DataFrame(no_reweigh_results)\n",
    "reweigh_results = pd.DataFrame(reweigh_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b6ee247-bc67-40de-b5fa-f5210c0970e7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "no_reweigh_results.to_excel(\"PHQ9_no_reweigh_results.xlsx\")\n",
    "reweigh_results.to_excel(\"PHQ9_reweigh_results.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fd732aa-7f8a-4490-b7ab-650c44013b84",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "no_reweigh_results = pd.read_excel(\"PHQ9_no_reweigh_results.xlsx\")\n",
    "reweigh_results = pd.read_excel(\"PHQ9_reweigh_results.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5de865b0-21c1-407d-a3a3-6102e27480d4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "no_reweigh_results['Race'] = no_reweigh_results['Race'].str[9:]\n",
    "reweigh_results['Race'] = reweigh_results['Race'].str[9:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "081ec556-39f8-440b-88b5-2f92c25e58d7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "no_reweigh_results['Race'] = no_reweigh_results['Race'].replace({'Asian or Native Hawaiian or Other Pacific Islander':'AAPI', \n",
    "                                                                 'Black or African American':'Black',\n",
    "                                                                 'Multiracial':'Multi',\n",
    "                                                                 'Hispanic White':'Hispanic'})\n",
    "reweigh_results['Race'] = reweigh_results['Race'].replace({'Asian or Native Hawaiian or Other Pacific Islander':'AAPI', \n",
    "                                                                 'Black or African American':'Black',\n",
    "                                                                 'Multiracial':'Multi',\n",
    "                                                                 'Hispanic White':'Hispanic'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9259db52-3a8c-4f1c-8d02-59db2b66eeb6",
   "metadata": {},
   "source": [
    "## No Reweighing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5b5d364-ae8d-4859-85ec-fc9f2de24cb4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sns.barplot(data=no_reweigh_results, x='Race', y='DP', hue='Model')\n",
    "plt.ylim((-0.8,0.8))\n",
    "plt.title('PHQ-9 Disparate Impact Before Reweighing')\n",
    "plt.savefig('No Reweigh DI.png',dpi=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "029d07cc-5cfe-4a96-b99a-ff21b040ad93",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sns.barplot(data=no_reweigh_results, x='Race', y='FN', hue='Model')\n",
    "plt.ylim((-0.8,0.8))\n",
    "plt.title('PHQ-9 False Negatives Before Reweighing')\n",
    "plt.savefig('No Reweigh FN.png',dpi=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e92c7797-af26-4372-9f94-3fec227e0c48",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sns.barplot(data=no_reweigh_results, x='Race', y='TP', hue='Model')\n",
    "plt.ylim((-0.8,0.8))\n",
    "plt.title('PHQ-9 True Positives Before Reweighing')\n",
    "plt.savefig('No Reweigh TP.png',dpi=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93527323-0c32-49cc-b1f7-69f5fc39454d",
   "metadata": {},
   "source": [
    "## With Reweighing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55914eb3-1f69-4c18-8f1c-bac6edb6abae",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sns.barplot(data=reweigh_results, x='Race', y='DP', hue='Model')\n",
    "plt.ylim((-0.8,0.8))\n",
    "plt.title('PHQ-9 Disparate Impact After Reweighing')\n",
    "plt.savefig('Reweigh DI.png',dpi=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d97da82a-971a-4be6-ba0b-a631853fba42",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sns.barplot(data=reweigh_results, x='Race', y='FN', hue='Model')\n",
    "plt.ylim((-0.8,0.8))\n",
    "plt.title('PHQ-9 False Negatives After Reweighing')\n",
    "plt.savefig('Reweigh FN.png',dpi=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36fe7ee6-5024-4a0b-839d-b76c0cdca7fa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sns.barplot(data=reweigh_results, x='Race', y='TP', hue='Model')\n",
    "plt.ylim((-0.8,0.8))\n",
    "plt.title('PHQ-9 True Positives After Reweighing')\n",
    "plt.savefig('Reweigh TP.png',dpi=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9f11594-5cca-4820-adf7-88f36b1ff098",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# save this file and output as html\n",
    "import os\n",
    "os.system('jupyter nbconvert --to html data_analysis_PHQ9.ipynb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6ebe1ba-0cc7-4669-abdc-d51f42e7d8ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.to_excel(\"X_train.xlsx\")\n",
    "y_train.to_excel(\"y_train.xlsx\")\n",
    "X_test.to_excel(\"X_test.xlsx\")\n",
    "y_test.to_excel(\"y_test.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e540101-8bae-4265-af8f-4429b2e3233e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
